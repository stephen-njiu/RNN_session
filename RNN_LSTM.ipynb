{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dddb37ee-387b-4ab8-b715-a934a4eb8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "# Suppress DeprecationWarning and FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e8a5ef-9b8c-4f6b-9ea3-624ff77598f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Preprocess both training and test data\n",
    "    \n",
    "    Parameters:\n",
    "    train_df (DataFrame): Training data\n",
    "    test_df (DataFrame): Test data\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Processed training data, processed test data, encoders, and scalers\n",
    "    \"\"\"\n",
    "    # Create copies to avoid modifying original data\n",
    "    train = train_df.copy()\n",
    "    test = test_df.copy()\n",
    "    \n",
    "    # Convert dates to datetime\n",
    "    train['date'] = pd.to_datetime(train['date'])\n",
    "    test['date'] = pd.to_datetime(test['date'])\n",
    "\n",
    "    \n",
    "    # Initialize encoders and scalers\n",
    "    family_encoder = LabelEncoder()\n",
    "    scalers = {\n",
    "        'sales': StandardScaler(),\n",
    "        'onpromotion': StandardScaler(),\n",
    "        'store_nbr': StandardScaler()\n",
    "    }\n",
    "    \n",
    "    # Encode categorical variables \n",
    "    train['family'] = family_encoder.fit_transform(train['family'])\n",
    "    test['family'] = family_encoder.transform(test['family'])\n",
    "    \n",
    "    # Scale numerical features\n",
    "    train['sales'] = scalers['sales'].fit_transform(train[['sales']])\n",
    "    \n",
    "    for col in ['onpromotion']:\n",
    "        train[f'{col}'] = scalers[col].fit_transform(train[[col]])\n",
    "        test[f'{col}'] = scalers[col].transform(test[[col]])\n",
    "    \n",
    "    return train, test, family_encoder, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32350b1a-1c9f-4603-ace2-e3e5d8fee3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
       "4   4  2013-01-01          1       BOOKS    0.0            0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "sub = pd.read_csv(\"store-sales-time-series-forecasting/sample_submission.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61dcba47-e446-4ce2-bd09-8f368c46eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, family_encoder, scalers = preprocess_data(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "523b7f27-b296-4b33-b002-d80b1ab08748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_sequences(train_df, time_steps=6):\n",
    "    \"\"\"\n",
    "    Create training sequences efficiently using grouped data\n",
    "    \n",
    "    Parameters:\n",
    "    train_df: DataFrame containing training data\n",
    "    time_steps: Number of previous time steps to use (default 6)\n",
    "    \n",
    "    Returns:\n",
    "    X_train: Array of input sequences\n",
    "    y_train: Array of target values\n",
    "    \"\"\"\n",
    "    # Sort the DataFrame by date within each group\n",
    "    train_df = train_df.sort_values(['store_nbr', 'family', 'date'])\n",
    "    \n",
    "    # Initialize lists to store sequences\n",
    "    X, y = [], []\n",
    "    \n",
    "    # Group by store_nbr and family\n",
    "    groups = train_df.groupby(['store_nbr', 'family'])\n",
    "    \n",
    "    # Iterate through each group\n",
    "    for _, group in tqdm(groups, desc=\"Creating train sequences\"):\n",
    "        # Convert relevant columns to numpy for faster processing\n",
    "        sales = group['sales'].values\n",
    "        features = group[['onpromotion', 'family','store_nbr']].values\n",
    "        \n",
    "        # Create sequences for this group\n",
    "        for i in range(len(group) - time_steps):\n",
    "            X.append(features[i:i+time_steps])\n",
    "            y.append(sales[i+time_steps])\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39af4dcf-b47f-4074-9e36-5949b52c2c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating train sequences: 100%|███████████████████████████████████████████████████| 1782/1782 [00:08<00:00, 205.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2990196, 6, 3), (2990196,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = create_train_sequences(train, 6)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49032ae9-f526-494f-831b-6bde7de5d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_complete_test_sequences(test_df, train_df, time_steps=6):\n",
    "    \"\"\"\n",
    "    Create test sequences for every single row in test_df with multiple features\n",
    "\n",
    "    Parameters:\n",
    "    test_df: DataFrame containing test data\n",
    "    train_df: DataFrame containing training data\n",
    "    time_steps: Number of previous time steps to use (default 6)\n",
    "\n",
    "    Returns:\n",
    "    X_test: Array of input sequences matching test_df length with multiple features\n",
    "    \"\"\"\n",
    "    # Combine train and test data, keeping only necessary columns\n",
    "    combined_df = pd.concat([\n",
    "        train_df[['id', 'date', 'store_nbr', 'family', 'onpromotion']],\n",
    "        test_df[['id', 'date', 'store_nbr', 'family', 'onpromotion']]\n",
    "    ]).sort_values(['store_nbr', 'family', 'date'])\n",
    "\n",
    "    # Initialize array to store all sequences (with 3 features now: family, store_nbr, onpromotion)\n",
    "    X_test = np.zeros((len(test_df), time_steps, 3))  # 3 features\n",
    "\n",
    "    # Create a dictionary for faster lookups, using (store_nbr, family) as the key\n",
    "    combined_dict = {}\n",
    "    for (store_nbr, family), group in combined_df.groupby(['store_nbr', 'family']):\n",
    "        combined_dict[(store_nbr, family)] = group\n",
    "\n",
    "    # Iterate through test_df\n",
    "    for idx, test_row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Creating test sequences\"):\n",
    "        store = test_row['store_nbr']\n",
    "        family = test_row['family']\n",
    "        test_date = test_row['date']\n",
    "\n",
    "        # Get the corresponding group using (store_nbr, family) as the key\n",
    "        group = combined_dict.get((store, family))\n",
    "\n",
    "        # # Handle cases where no matching group is found (if any)\n",
    "        # if group is None:\n",
    "        #     continue  # or handle as needed (e.g., set sequence to zeros)\n",
    "\n",
    "        # Find the index of the current test date in this group\n",
    "        try:\n",
    "            date_idx = group[group['date'] == test_date].index[0]\n",
    "            group_date_idx = list(group.index).index(date_idx)\n",
    "        except IndexError:\n",
    "            # Handle missing date in the group (if necessary)\n",
    "            print(\"problem with the data\")\n",
    "\n",
    "        # Create sequence for multiple features: family, store_nbr, onpromotion\n",
    "        sequence = np.zeros((time_steps, 3))  # 3 features in the sequence\n",
    "\n",
    "        for i in range(time_steps):\n",
    "            if group_date_idx - (time_steps - i) >= 0:\n",
    "                # Feature 1: family\n",
    "                sequence[i, 0] = group.iloc[group_date_idx - (time_steps - i)]['family']\n",
    "                # Feature 2: store_nbr\n",
    "                sequence[i, 1] = group.iloc[group_date_idx - (time_steps - i)]['store_nbr']\n",
    "                # Feature 3: onpromotion\n",
    "                sequence[i, 2] = group.iloc[group_date_idx - (time_steps - i)]['onpromotion']\n",
    "\n",
    "        # Store the sequence in X_test\n",
    "        X_test[idx] = sequence\n",
    "\n",
    "    return X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9703a932-1b4f-4f16-8675-c0db86f92a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating test sequences: 100%|██████████████████████████████████████████████████| 28512/28512 [01:51<00:00, 254.88it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test = create_complete_test_sequences(test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e0e8098-50e5-40f7-b1db-8ff6139ec369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28512, 6, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0da45d9-2d24-48c4-a763-52d09e83c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building function\n",
    "def build_model(input_shape):\n",
    "    \"\"\"\n",
    "    Build and compile the LSTM model\n",
    "    \n",
    "    Parameters:\n",
    "    input_shape (tuple): Shape of input data\n",
    "    \n",
    "    Returns:\n",
    "    Sequential: Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # Define the input layer explicitly\n",
    "    model.add(Input(shape=input_shape))\n",
    "    \n",
    "    # First LSTM layer with Dropout to prevent overfitting\n",
    "    model.add(LSTM(units=32, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(units=16, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Dense layer for output\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_logarithmic_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98eab272-3def-4fa3-8f9c-de5754f8fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model((6,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1edb9d33-471e-4338-a7c2-2544c5ce5dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │           \u001b[38;5;34m4,608\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m3,136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,761</span> (30.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,761\u001b[0m (30.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,761</span> (30.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,761\u001b[0m (30.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1b5e13e-fbef-4394-9a6e-e5fbefe21e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, epochs=2, batch_size = 64):\n",
    "    \"\"\"\n",
    "    Train the LSTM model\n",
    "    \n",
    "    Parameters:\n",
    "    model: Compiled Keras model\n",
    "    X_train: Training sequences\n",
    "    y_train: Target values\n",
    "    epochs (int): Number of epochs to train\n",
    "    batch_size (int): Batch size for training\n",
    "    validation_split (float): Fraction of data to use for validation\n",
    "    \n",
    "    Returns:\n",
    "    History: Training history\n",
    "    \"\"\"\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size = batch_size,\n",
    "        verbose=True\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c7c35-c1c9-4cb0-94e6-f4eac9c83787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m20558/46722\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4:00\u001b[0m 9ms/step - loss: 0.0323"
     ]
    }
   ],
   "source": [
    "history = train_model(model, x, y)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a392c89-be2f-4e9e-a14d-0180ddf17d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e5e93-b2db-47e4-93b4-8b7f1e671314",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_scaled = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05184996-1d28-493b-8ee7-b5f47e7fb059",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scalers['sales'].inverse_transform(predictions_scaled)\n",
    "predictions = predictions.flatten()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855caae4-5187-4961-8924-7021c9eb0399",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['sales'] = predictions\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23cdc82-8e2b-444a-ae45-609e7b38486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2d45c-59a2-4ccf-90af-f7a46198598c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b198e72-b815-46fd-8cad-df914c11ca2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48960e28-7758-4073-9319-aaa34c68da8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3113f51-f7a0-46cc-8c2e-e4fae4ed4b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
